import os

import json

import streamlit as st

from langchain.agents import initialize_agent, Tool

from langchain_openai import OpenAI

# OpenAI API 키 설정

os.environ["OPENAI_API_KEY"] = ''
# JSON 파일에서 예제 로드

@st.cache_data

def load_examples():

examples_path = "Franka_ex.json"

if not os.path.exists(examples_path):

raise FileNotFoundError(f"Examples file not found: {examples_path}")

with open(examples_path, "r") as file:

return json.load(file)

examples = load_examples()

# LLM 응답 처리 함수

def parse_llm_response(response):

if isinstance(response, dict):

# OpenAI 응답 형식에 따른 텍스트 추출

if "choices" in response and len(response["choices"]) > 0:

response_text = response["choices"][0].get("text", "")

else:

raise ValueError("Invalid response format: 'choices' key is missing.")

else:

response_text = response  # 이미 문자열이라면 그대로 사용

# 문자열을 줄 단위로 분리

return response_text

# 프롬프트를 사용한 예제 검색 함수

def search_examples_with_llm(query: str) -> str:

examples_text = "\n".join(

[f"Title: {example['title']}\nDescription: {example['description']}\nCode: {example['code']}" for example in examples]

)

prompt = f"""

You are a helpful assistant for finding the most relevant Franka example.

Below are multiple examples of Franka robot-related code, each with a title, description, and code block.

Identify the most relevant example based on the user's query.

User Query: "{query}"

Examples: {examples_text}

Respond with the code block of the most relevant example only.

If no example is relevant, respond with "No matching example found."

"""

# LLM 호출

response = llm(prompt)

# 응답 처리

if isinstance(response, dict) and "choices" in response:

response_text = response["choices"][0].get("text", "").strip()

else:

response_text = response.strip()

# 코드 부분만 추출

if "No matching example found" in response_text or len(response_text) == 0:

return "No matching example found. Please provide a more specific query or include more details."

# 정확히 코드 블록만 추출

if "```python" in response_text:

start_index = response_text.find("```python") + len("```python")

end_index = response_text.find("```", start_index)

return response_text[start_index:end_index].strip()

return response_text

# LangChain 도구 초기화

franka_tool_llm = Tool(

name="SearchFrankaExamplesWithLLM",

func=search_examples_with_llm,

description="Find the most relevant Franka example using a language model."

)

# OpenAI LLM 인스턴스 생성

llm = OpenAI(model="gpt-3.5-turbo-instruct", temperature=0)

# Streamlit 인터페이스

st.title("Franka Robot Code Finder")

# 사용자 입력

user_request = st.text_input("Enter the task you want to perform:")

if user_request:

with st.spinner("Searching for the best matching code..."):

response = search_examples_with_llm(user_request)  # LangChain 호출

st.code(response, language="python")  # Python 코드 형식으로 출력
